---
title: "TITLE: Practical Machine Learning - Prediction Assignment"
output: 
  html_document:
    keep_md: true
author: "Author: Stephen Lye"
date: "Date: 8 October 2015"
---

## OVERVIEW

The purpose of this project is build a machine learning algorithm to predict activity quality from activity monitors.

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

<font color = 'Red'>
Note: The data for this project comes from this source: http://groupware.les.inf.puc-rio.br/har
</font>

### STEP 1 - INITIAL SETUP AND LOAD LIBRARIES
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
# Clear Workspace
rm(list=ls())

# Load Libraries
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
```

### STEP 2 - LOAD DATA
```{r echo = TRUE, cache = TRUE, message = FALSE, error = FALSE, warning = FALSE}
# Download source data files
SrcURL <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
DestFile <- 'pml-training.csv'
if(!file.exists(DestFile)) {download.file(url = SrcURL, destfile = DestFile, cacheOK = TRUE)}

# Read Data
if(!exists('df_Train')) {df_Train <- read.csv(DestFile, header = TRUE, sep = ',')}
```

Show the number of **Rows** and **Columns** of data

Data Rows = `r format(dim(df_Train)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Train)[2], big.mark = ',')`

Show a **Sample** of the data
```{r echo = TRUE}
head(df_Train, 2L)
```

Show the **column names** of the data
```{r echo = TRUE}
names(df_Train)
```

### STEP 3 - CLEAN THE DATA
Before we start building the models for prediction, we must first clean up the raw data by removing columns that are not required for analysis, removing columns with mostly NA data and removing data with Near Zero Variance (NZV).

REMOVE UNNECESSARY COLUMNS 1 - 7 AS IT IS NOT MEANINGFUL FOR ANALYSIS
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
df_Train <- df_Train[, -c(1:7)]
```

Show the number of **Rows** and **Columns** of data **after removing the unnecessary columns**

Data Rows = `r format(dim(df_Train)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Train)[2], big.mark = ',')`

REMOVE COLUMNS WITH 70% NA VALUES
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
Cutoff_Level <- nrow(df_Train) * 0.7
df_Train <- df_Train[, colSums(is.na(df_Train)) <= Cutoff_Level]
```

Show the number of **Rows** and **Columns** of data **after removing the columns with at least 70% of NA values**

Data Rows = `r format(dim(df_Train)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Train)[2], big.mark = ',')`

REMOVE COLUMNS WITH NEAR ZERO VARIANCE (NZV)
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
Train_NZV <- nearZeroVar(df_Train, saveMetrics = TRUE)
Cols2Keep <- rownames(Train_NZV[Train_NZV$nzv == FALSE, ])
df_Train <- df_Train[Cols2Keep]
```

Show the number of **Rows** and **Columns** of data **after removing the columns with Near Zero Variance (NZV)**

Data Rows = `r format(dim(df_Train)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Train)[2], big.mark = ',')`

### STEP 4 - SPLIT DATA INTO 2 SETS FOR ANALYSIS
After performing the data cleaning, we now split the original data set into 2 - the 1st set is for data sampling and the 2nd set is for cross validation.

SPLIT THE ORIGINAL DATA SET INTO 2 SEPARATE DATA SETS - ONE WITH 60% OF THE ORIGINAL DATA AND THE OTHER WITH THE REMAINING 40%.
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
InclData <- createDataPartition(y = df_Train$classe, p = 0.6, list = FALSE)
df_Train_60 <- df_Train[InclData, ]
df_Train_40 <- df_Train[-InclData, ]
```

REMOVE ORIGINAL DATA SET AS IT IS NO LONGER REQUIRED
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
rm(df_Train)
```

Show the number of **Rows** and **Columns** of data from **Data Set 1 (df_Train_60) which has 60% of the data from the original data set**

Data Rows = `r format(dim(df_Train_60)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Train_60)[2], big.mark = ',')`

Show the number of **Rows** and **Columns** of data from **Data Set 2 (df_Train_40) which has 40% of the data from the original data set**

Data Rows = `r format(dim(df_Train_40)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Train_40)[2], big.mark = ',')`

### STEP 5 - PERFORM MACHINE LEARNING ON DECISION TREE
After our data sets have been prepared, we now proceed to **build the appropriate prediction models using Machine Learning**. We first start with a **Decision Tree** model.

```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
# Set seed
set.seed(1000)

# Use ML Algo for prediction - Decision Tree
PredictionModel1 <- rpart(classe ~ ., data = df_Train_60, method = 'class')

# Perform prediction
DT_Prediction <- predict(PredictionModel1, df_Train_40, type = 'class')
```

### STEP 6 - VIEW DECISION TREE
We **view the contents of the Decision Tree** as shown below:-
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
print(PredictionModel1)
```

### STEP 7 - VISUALISE DECISION TREE
We **visualise the Decision Tree** by the plot below:-
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE, fig.height = 8.5, fig.width = 9.5}
fancyRpartPlot(PredictionModel1, cex = .5, under.cex = 1, shadow.offset = 0)
```

### STEP 8 - SHOW DECISION TREE RESULTS
We now show the results of the **Decision Tree** prediction model by using the **Confusion Matrix**.

```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE, results = 'markup'}
Results <- confusionMatrix(DT_Prediction, df_Train_40$classe)
Results
```
```{r echo = FALSE}
Model1_Accuracy <- as.character(Results)
Model1_Accuracy <- round(as.numeric(substring(Model1_Accuracy[3], 3, 10)), digits = 4)
```

The result shows that the accuracy of this model is only **`r Model1_Accuracy`** ie. **`r Model1_Accuracy * 100`%** accurate. This is **not good enough**.

### STEP 9 - PERFORM MACHINE LEARNING ON RANDOM FOREST
As the previous prediction model didn't provide us with a high level of accuracy, we will now proceed to **build a better prediction model** by using the **Random Forest** method.

```{r echo = TRUE}
# Use ML Algo for prediction - Random Forest
PredictionModel2 <- randomForest(classe ~. , data = df_Train_60)

# Perform prediction
RF_Prediction <- predict(PredictionModel2, df_Train_40, type = 'class')
```

### STEP 10 - SHOW RANDOM FOREST RESULTS
We now show the results of the **Random Forest** prediction model by using the **Confusion Matrix**.

```{r echo = TRUE}
Results <- confusionMatrix(RF_Prediction, df_Train_40$classe)
Results
```
```{r echo = FALSE}
Model2_Accuracy <- as.character(Results)
Model2_Accuracy <- round(as.numeric(substring(Model2_Accuracy[3], 3, 10)), digits = 4)
```

The result shows that the accuracy of this model is **`r Model2_Accuracy`** ie. **`r Model2_Accuracy * 100`%** accurate. This is **good enough**.

### STEP 11 - SHOW EXPECTED OUT OF SAMPLE ERROR
Out of Sample Error is calculated as `1 - Accuracy`.

For the **1st Prediction Model** using **Decision Tree**,  
the **Accuracy** = **`r Model1_Accuracy`**  
and the **Out of Sample Error** = 1 - `r Model1_Accuracy` = **`r 1 - Model1_Accuracy`**

For the **2nd Prediction Model** using **Random Forest**,  
the **Accuracy** = **`r Model2_Accuracy`**  
and the **Out of Sample Error** = 1 - `r Model2_Accuracy` = **`r 1 - Model2_Accuracy`**

## CONCLUSION

Based on the results of the **Confusion Matrix** and **Out of Sample Error** on both prediction models, it shows that the **Random Forest model is far more accurate and more reliable** than the **Decision Tree** model.

Since the **Random Forest model is the most accurate model** that we can derive thus far and the **Out of Sample Error is very small**, we will use it for Part 2 of the assignment to predict the outcome from a set of Test Data.

## ASSIGNMENT PART 2

### PART 2 STEP 1 - LOAD TEST DATA
```{r echo = TRUE, message = FALSE, error = FALSE, warning = FALSE}
SrcURL <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
DestFile <- 'pml-testing.csv'

if(!exists('df_Test')) {df_Test <- read.csv(DestFile, header = TRUE, sep = ',')}
```

Show the number of **Rows** and **Columns** of data

Data Rows = `r format(dim(df_Test)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Test)[2], big.mark = ',')`

### PART 2 STEP 2 - CONVERT TEST DATA TO HAVE THE SAME COLUMNS AS THE TRAINING DATA
```{r echo = TRUE}
# Remove last column (classe) as it is not required
Cols2Keep <- colnames(df_Train_60[, -ncol(df_Train_60)])
df_Test <- df_Test[Cols2Keep]
```

Show the number of **Rows** and **Columns** of data **after converting the columns in the test data to be the same as the training data**

Data Rows = `r format(dim(df_Test)[1], big.mark = ',')`  
Data Columns = `r format(dim(df_Test)[2], big.mark = ',')`

### PART 2 STEP 3 - DEFINE FUNCTION TO GENERATE RESULTS FILES FOR SUBMISSION
```{r echo = TRUE}
pml_write_files = function(x) {
  n = length(x)
  for(i in 1:n) {
      filename = paste0("./Part2_Results/problem_id_",i,".txt")
      write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
```

### PART 2 STEP 4 - PERFORM PREDICTION - USE **RANDOM FOREST** MODEL AS IT IS THE BEST
```{r echo = TRUE}
RF_Prediction_Test <- predict(PredictionModel2, df_Test, type = 'class')
```

### PART 2 STEP 5 - SHOW THE RESULTS OF THE PREDICTION
```{r echo = TRUE}
RF_Prediction_Test
```

### PART 2 STEP 6 - OUTPUT THE RESULTS TO TEXT FILES
```{r echo = TRUE}
pml_write_files(RF_Prediction_Test)
```

### ~ END ~
